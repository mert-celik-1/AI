from dotenv import load_dotenv
import os
import requests
import gradio as gr
import re
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain.chat_models import init_chat_model
from langchain_chroma import Chroma
from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain.tools import tool
from pydantic import BaseModel, Field
from typing import Optional, List

load_dotenv(override=True)

openai_api_key = os.getenv('OPENAI_API_KEY')

model = init_chat_model("gpt-4o-mini", model_provider="openai", streaming=True)

pdf_paths = ["attention.pdf", "avelandia.pdf"]

pdf_docs = []
for path in pdf_paths:
    loader = PyPDFLoader(path)
    pdf_docs.extend(loader.load())

web_loader = WebBaseLoader(
    "https://cbarkinozer.medium.com/transformat%C3%B6rler-t%C3%BCm-i%CC%87htiyac%C4%B1n%C4%B1z-olan-dikkat-ee4ff66723b1")
web_docs = web_loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, separators=["\n\n", "\n", " ", ""])
chunks = text_splitter.split_documents(pdf_docs + web_docs)

embeddings = OpenAIEmbeddings()

if os.path.exists("./chroma_db"):
    vectorstore = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)
else:
    vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory="./chroma_db")
    vectorstore.persist()
retriever = vectorstore.as_retriever()


def format_docs(docs):
    content = "\n\n".join(doc.page_content for doc in docs)
    return clean_text(content)


message_histories = {}


def get_session_history(session_id):
    if session_id not in message_histories:
        message_histories[session_id] = ChatMessageHistory()
    return message_histories[session_id]


def clean_text(text):
    return text.encode('utf-8', errors='ignore').decode('utf-8')


@tool
def get_weather(location: str) -> str:
    """Belirli bir konumun gÃ¼ncel hava durumunu API'den Ã§eker."""
    try:
        api_key = os.getenv("OPENWEATHER_API_KEY")
        if not api_key:
            return "API anahtarÄ± bulunamadÄ±. OPENWEATHER_API_KEY Ã§evre deÄŸiÅŸkenini ayarlayÄ±n."

        base_url = "https://api.openweathermap.org/data/2.5/weather"
        params = {
            "q": location,
            "appid": api_key,
            "units": "metric",
            "lang": "tr"
        }

        response = requests.get(base_url, params=params)
        response.raise_for_status()

        data = response.json()

        weather_description = data["weather"][0]["description"]
        temperature = data["main"]["temp"]
        feels_like = data["main"]["feels_like"]
        humidity = data["main"]["humidity"]
        wind_speed = data["wind"]["speed"]

        result = f"{location} iÃ§in hava durumu:\n"
        result += f"Durum: {weather_description}\n"
        result += f"SÄ±caklÄ±k: {temperature}Â°C (Hissedilen: {feels_like}Â°C)\n"
        result += f"Nem: %{humidity}\n"
        result += f"RÃ¼zgar HÄ±zÄ±: {wind_speed} m/s"

        return result

    except requests.exceptions.HTTPError as http_err:
        if 'response' in locals() and response.status_code == 404:
            return f"'{location}' konumu bulunamadÄ±. LÃ¼tfen geÃ§erli bir ÅŸehir veya Ã¼lke adÄ± girin."
        else:
            return f"HTTP hatasÄ±: {http_err}"
    except requests.exceptions.RequestException as req_err:
        return f"Ä°stek hatasÄ±: {req_err}"
    except KeyError as key_err:
        return f"API yanÄ±tÄ±nda beklenen veri bulunamadÄ±: {key_err}"
    except Exception as e:
        return f"Beklenmeyen hata: {str(e)}"


tools = [get_weather]

agent_prompt = ChatPromptTemplate.from_messages([
    ("system", """AkÄ±llÄ± bir asistansÄ±n. KullanÄ±cÄ± sorularÄ±nÄ± yanÄ±tlamak ve Ã§eÅŸitli gÃ¶revleri yerine getirmek iÃ§in araÃ§larÄ± kullanabilirsin.

    Elinde ÅŸu araÃ§lar var:
    1. Hava durumu bilgisi alma

    AraÃ§larÄ± kullanÄ±rken doÄŸru parametreleri saÄŸladÄ±ÄŸÄ±ndan emin ol. KullanÄ±cÄ±nÄ±n isteÄŸini anla ve en uygun aracÄ± seÃ§.

    AraÃ§ kullanÄ±mÄ± gerekmeyen sorular iÃ§in kendi bilgilerinle yanÄ±t ver.

    KULLANICI TARAFINDAN BELÄ°RTÄ°LEN DÄ°L: {language}. Bu dilde yanÄ±t vermeyi unutma."""),
    ("human", "{question}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

agent = create_openai_functions_agent(model, tools, agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)


class CriticResult(BaseModel):
    is_hallucination: bool = Field(description="YanÄ±tÄ±n bir halÃ¼sinasyon iÃ§erip iÃ§ermediÄŸi")
    score: int = Field(description="YanÄ±tÄ±n doÄŸruluk puanÄ± (1-10 arasÄ±)")
    issues: Optional[List[str]] = Field(description="Tespit edilen sorunlar listesi")
    corrected_response: Optional[str] = Field(description="DÃ¼zeltilmiÅŸ yanÄ±t")
    reasoning: str = Field(description="DeÄŸerlendirme gerekÃ§esi")


@tool
def analyze_response(response_text: str) -> str:
    """Verilen yanÄ±tÄ± analiz eder. Bu sadece critic agent'Ä±n OpenAI fonksiyonlarÄ± iÃ§in gerekli bir fonksiyondur."""
    return "Analiz tamamlandÄ±."


critic_tools = [analyze_response]

critic_prompt = ChatPromptTemplate.from_messages([
    ("system", """Sen bir yanÄ±t deÄŸerlendirme uzmanÄ±sÄ±n. KullanÄ±cÄ± sorusuna ve AI tarafÄ±ndan verilen cevaba dayanarak, 
    cevabÄ±n doÄŸruluÄŸunu deÄŸerlendir ve halÃ¼sinasyon iÃ§erip iÃ§ermediÄŸini belirle.

    DeÄŸerlendirmeni aÅŸaÄŸÄ±daki formatta yap:

    IS_HALLUCINATION: [true/false] - YanÄ±t halÃ¼sinasyon iÃ§eriyor mu?
    SCORE: [1-10] - YanÄ±tÄ±n doÄŸruluk puanÄ±
    ISSUES: [liste] - Tespit edilen sorunlar
    REASONING: [aÃ§Ä±klama] - DeÄŸerlendirme gerekÃ§en
    CORRECTED_RESPONSE: [dÃ¼zeltilmiÅŸ yanÄ±t] - Gerekiyorsa yanÄ±tÄ± dÃ¼zelt

    DeÄŸerlendirme yaparken:
    1. YanÄ±tÄ±n, kullanÄ±cÄ± sorusuyla alakalÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et
    2. YanÄ±ttaki bilgilerin doÄŸruluk derecesini deÄŸerlendir
    3. EÄŸer halÃ¼sinasyon (uydurma bilgi) tespit edersen, hangi kÄ±sÄ±mlarÄ±n sorunlu olduÄŸunu belirt
    4. Sorunlu yanÄ±tlarÄ± dÃ¼zelt veya belirsizliÄŸi azalt
    5. YanÄ±ta 1-10 arasÄ± bir doÄŸruluk puanÄ± ver
    """),
    ("human", """KullanÄ±cÄ± Sorusu: {question}

    AI YanÄ±tÄ±: {ai_response}

    LÃ¼tfen bu yanÄ±tÄ± deÄŸerlendir."""),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

critic_model = init_chat_model("gpt-4o-mini", model_provider="openai", streaming=False)
critic_agent = create_openai_functions_agent(critic_model, critic_tools, critic_prompt)
critic_executor = AgentExecutor(agent=critic_agent, tools=critic_tools, verbose=True)


def evaluate_response(question, ai_response):
    try:
        evaluation_result = critic_executor.invoke({
            "question": question,
            "ai_response": ai_response
        })

        response_text = evaluation_result["output"]

        is_hallucination = "IS_HALLUCINATION: true" in response_text.upper()

        score_match = re.search(r"SCORE:\s*(\d+)", response_text, re.IGNORECASE)
        score = int(score_match.group(1)) if score_match else 5

        issues_section = re.search(r"ISSUES:(.*?)(?:REASONING:|CORRECTED_RESPONSE:|$)",
                                   response_text, re.IGNORECASE | re.DOTALL)
        issues = []
        if issues_section:
            issues_text = issues_section.group(1).strip()
            issues = [issue.strip() for issue in issues_text.split("\n") if issue.strip()]

        corrected_section = re.search(r"CORRECTED_RESPONSE:(.*?)(?:$)",
                                      response_text, re.IGNORECASE | re.DOTALL)
        corrected_response = corrected_section.group(1).strip() if corrected_section else None

        reasoning_section = re.search(r"REASONING:(.*?)(?:CORRECTED_RESPONSE:|$)",
                                      response_text, re.IGNORECASE | re.DOTALL)
        reasoning = reasoning_section.group(1).strip() if reasoning_section else "DeÄŸerlendirme yapÄ±lamadÄ±."

        result = CriticResult(
            is_hallucination=is_hallucination,
            score=score,
            issues=issues,
            corrected_response=corrected_response,
            reasoning=reasoning
        )

        return result

    except Exception as e:
        print(f"Critic Agent hatasÄ±: {str(e)}")
        return CriticResult(
            is_hallucination=False,
            score=5,
            issues=["DeÄŸerlendirme sÄ±rasÄ±nda teknik bir hata oluÅŸtu."],
            corrected_response=None,
            reasoning="DeÄŸerlendirme yapÄ±lamadÄ±."
        )


def respond(message, chat_history, language, show_debug=False):
    session_id = "gradio_session"

    chat_history.append({"role": "user", "content": message})
    chat_history.append({"role": "assistant", "content": ""})

    yield chat_history, ""

    try:
        print("\n=== MAIN AGENT EXECUTION ===")
        response = agent_executor.invoke({
            "question": message,
            "language": language
        })

        initial_response = response["output"]
        print(f"\nÄ°lk yanÄ±t: {initial_response}\n")

        print("\n=== CRITIC AGENT EXECUTION ===")
        evaluation = evaluate_response(message, initial_response)
        print(f"\nDeÄŸerlendirme sonucu: {evaluation}\n")

        if evaluation.is_hallucination and evaluation.corrected_response:
            final_response = f"{evaluation.corrected_response}"

            if show_debug:
                final_response += f"\n\n---\n*Bu yanÄ±t dÃ¼zeltildi.*\n"
                final_response += f"*GÃ¼venilirlik puanÄ±: {evaluation.score}/10*\n"
                final_response += f"*Sorunlar: {', '.join(evaluation.issues)}*\n"
                final_response += f"*GerekÃ§e: {evaluation.reasoning}*"
        else:
            final_response = initial_response

            if show_debug:
                final_response += f"\n\n---\n*GÃ¼venilirlik puanÄ±: {evaluation.score}/10*\n"
                if evaluation.reasoning:
                    final_response += f"*DeÄŸerlendirme: {evaluation.reasoning}*"

        if "data:image/png;base64," in final_response:
            image_parts = final_response.split("data:image/png;base64,")
            text_part = image_parts[0]
            image_data = image_parts[1].split('"')[0] if '"' in image_parts[1] else image_parts[1]

            final_response = f"{text_part}\n\n<img src='data:image/png;base64,{image_data}' alt='OluÅŸturulan Grafik'>"

        chat_history[-1]["content"] = final_response
        yield chat_history, ""

    except Exception as e:
        error_message = f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
        chat_history[-1]["content"] = error_message
        yield chat_history, ""


with gr.Blocks(title="Agentic RAG AsistanÄ±") as demo:
    gr.Markdown("# Agentic RAG AsistanÄ±")
    gr.Markdown("""Bu asistan, metin tabanlÄ± sorulara cevap vermenin yanÄ± sÄ±ra aÅŸaÄŸÄ±daki araÃ§larÄ± kullanabilir:

    - ğŸŒ¤ï¸ Hava durumu bilgisi

    Asistan ayrÄ±ca yanÄ±tlarÄ±nÄ± kontrol eden bir deÄŸerlendirme sistemi iÃ§erir ve halÃ¼sinasyonlarÄ± Ã¶nlemeye Ã§alÄ±ÅŸÄ±r.
    """)

    with gr.Row():
        language_dropdown = gr.Dropdown(
            choices=["TÃ¼rkÃ§e", "Ä°ngilizce", "Almanca", "FransÄ±zca", "Ä°spanyolca"],
            value="TÃ¼rkÃ§e",
            label="YanÄ±t Dili"
        )

        show_debug = gr.Checkbox(
            label="DeÄŸerlendirme Bilgilerini GÃ¶ster",
            value=False
        )

    chatbot = gr.Chatbot(height=500, type="messages")
    msg = gr.Textbox(placeholder="Sorunuzu buraya yazÄ±n veya bir araÃ§ kullanmak istediÄŸinizi belirtin...",
                     label="MesajÄ±nÄ±z")
    clear = gr.Button("Sohbeti Temizle")

    msg.submit(respond, [msg, chatbot, language_dropdown, show_debug], [chatbot, msg])
    clear.click(lambda: [], None, chatbot, queue=False)

if __name__ == "__main__":
    demo.queue()
    demo.launch(share=False)